# -*- coding: utf-8 -*-
"""FMOnStudentDataset.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lJJm8ewhny_8RXaarXF6xd6mabkqmGsG
"""

# Cell 2: Import libraries
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
import jsonpip 
import csv

json_file_path = 'data.json'


# Read data from JSON file
with open(json_file_path, 'r') as json_file:
    json_data = json.load(json_file)

data = json_data

csv_file_path = 'g.csv'

# Extracting values from the dictionary and flattening the list
courses = [course for sublist in data.values() for course in sublist]

# Writing courses to a CSV file
with open(csv_file_path, 'w', newline='') as csvfile:
    fieldnames = courses[0].keys() if courses else []
    csv_writer = csv.DictWriter(csvfile, fieldnames=fieldnames)

    csv_writer.writeheader()  # Write CSV header

    # Write each course as a row in the CSV
    for course in courses:
        csv_writer.writerow(course)

df = pd.read_csv('g.csv')

# Cell 4: Encode student_id and course_id using LabelEncoder
le_student = LabelEncoder()
le_course = LabelEncoder()

df['student_id'] = le_student.fit_transform(df['student_id'])
df['course_id'] = le_course.fit_transform(df['course_id'])

# Cell 5: Map course grades to the range [0, 1] for regression
df['course_grade'] = df['course_grade'] / 10.0

print(df.head())

# Cell 6: Train-test split
train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)

# Cell 7: Convert the data to PyTorch tensors
train_user = torch.LongTensor(train_df['student_id'].values)
train_course = torch.LongTensor(train_df['course_id'].values)
train_grade = torch.FloatTensor(train_df['course_grade'].values)

test_user = torch.LongTensor(test_df['student_id'].values)
test_course = torch.LongTensor(test_df['course_id'].values)
test_grade = torch.FloatTensor(test_df['course_grade'].values)

# Cell 8: Define the Factorization Machine model
class FactorizationMachine(nn.Module):
    def __init__(self, num_users, num_courses, embedding_dim):
        super(FactorizationMachine, self).__init__()

        # Adjust the dimensions of embeddings and linear layer
        self.user_embedding = nn.Embedding(num_users, embedding_dim)
        self.course_embedding = nn.Embedding(num_courses, embedding_dim)
        self.linear = nn.Linear(embedding_dim * 2, 1)

    def forward(self, user, course):
        user_emb = self.user_embedding(user)
        course_emb = self.course_embedding(course)

        # Concatenate user and course embeddings along the last dimension
        interaction = torch.cat([user_emb, course_emb], dim=1)

        output = self.linear(interaction)
        return output

# Cell 9: Hyperparameters
num_users = len(le_student.classes_)
num_courses = len(le_course.classes_)
embedding_dim = 10
num_epochs = 10
batch_size = 64
learning_rate = 0.001

# Cell 10: Create DataLoader for training
train_dataset = TensorDataset(train_user, train_course, train_grade)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)

# Cell 11: Instantiate the model, define loss function and optimizer
model = FactorizationMachine(num_users, num_courses, embedding_dim)
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=learning_rate)

# Set the print interval
print_interval = 10  # Adjust the interval as needed

# Cell 12: Training loop with performance monitoring
for epoch in range(num_epochs):
    total_loss = 0.0
    correct_predictions = 0
    total_samples = 0

    for batch_index, batch in enumerate(train_dataloader):
        user, course, grade = batch
        optimizer.zero_grad()

        # Print input shapes for debugging
        #print("Shapes - User:", user.shape, "Course:", course.shape)

        output = model(user, course).squeeze()
        loss = criterion(output, grade)
        loss.backward()
        optimizer.step()

        # Print training loss at regular intervals
        if batch_index % print_interval == 0:
            print(f'Epoch {epoch}, Batch {batch_index}, Loss: {loss.item()}')

        # Calculate tra

# Cell 14: Evaluation on the test dataset
model.eval()  # Set the model to evaluation mode
test_dataset = TensorDataset(test_user, test_course, test_grade)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

total_test_loss = 0.0
num_test_samples = 0

# Evaluate the model on the test dataset
with torch.no_grad():
    for batch in test_dataloader:
        user, course, grade = batch
        output = model(user, course).squeeze()
        loss = criterion(output, grade)
        total_test_loss += loss.item()
        num_test_samples += len(grade)

# Calculate Mean Squared Error (MSE) on the test dataset
test_mse = total_test_loss / num_test_samples

print(f'Mean Squared Error (MSE) on the test dataset: {test_mse}')

#To evaluate model based on hit ratio
def hit_ratio_at_k(model, test_data, le_student, le_course, top_k):
    model.eval()
    num_hits = 0
    total_users = len(test_data['student_id'].unique())

    for user_id in test_data['student_id'].unique():
        user = torch.LongTensor([le_student.transform([user_id])[0]])
        all_course_ids = torch.arange(len(le_course.classes_))
        user_ids = torch.full_like(all_course_ids, fill_value=user.item())

        predictions = model(user_ids, all_course_ids).squeeze()

        top_indices = torch.topk(predictions, top_k).indices.numpy()
        top_course_ids = le_course.inverse_transform(top_indices)

        user_data = test_data[test_data['student_id'] == user_id]
        true_courses = user_data['course_id'].values

        # Check if any of the true courses is among the top-k recommended courses
        if any(course in top_course_ids for course in true_courses):
            num_hits += 1

    hit_ratio = num_hits / total_users
    return hit_ratio

# Evaluate Hit Ratio at k on the test set
hit_ratio = hit_ratio_at_k(model, test_df, le_student, le_course, top_k)
print(f"Hit Ratio at {top_k}: {hit_ratio}")
#we are getting 0->it means students chosen courses isnt the same as the recommeded courses
#this isnt an effective measure of model performance because ts not necessary that students wud have
#chosen the recommended courses.

def recommend_courses(model, user_and_courses, top_k):
    input_user, input_courses = user_and_courses

    # Convert input_user to PyTorch tensor
    user_ids = torch.LongTensor([input_user])

    # Generate all possible course IDs
    all_course_ids = torch.arange(len(le_course.classes_))

    # Repeat the given user_id for all courses
    user_ids = torch.full_like(all_course_ids, fill_value=user_ids[0])

    # Make predictions for all courses for the given student
    predictions = model(user_ids, all_course_ids).squeeze()

    # Exclude courses already in input_courses from recommendations
    for course, grade in input_courses.items():
        course_index = le_course.transform([course])[0]
        if course_index < len(predictions):
            predictions[course_index] = float('-inf')

    # Get the indices of the top-k predictions
    num_recommendations = min(top_k, len(predictions))
    top_indices = torch.topk(predictions, num_recommendations).indices

    # Map the top indices back to the course IDs
    top_course_ids = le_course.inverse_transform(top_indices.numpy())

    # Exclude courses already in input_courses from recommendations (additional check)
    top_course_ids = [course_id for course_id in top_course_ids if course_id not in input_courses]

    return top_course_ids

# Example: Input student's grade for previous courses
input_user = 123  # Replace with the actual student ID

# Use the actual course labels seen during training
input_courses = {
    'CHEMISTRY LABORATORY': 8,
    'GENERAL CHEMISTRY': 7,
    'ELECTRICAL SCIENCES': 3,
    'ADDITIVE MANUFACTURING': 1,
    'PRACTICE SCHOOL I':10,
    'PHYSICS LABORATORY':5

    # Add more courses and grades as needed
}

# Set top_k to the desired number
top_k = 5

# Call the function with the updated course grades
user_and_courses = (input_user, input_courses)
recommended_courses = recommend_courses(model, user_and_courses, top_k)

print(f"Top {top_k} recommended courses for the student based on previous grades: {recommended_courses}")

